{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYZeSdwwRiLx"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set(style=\"white\", color_codes=True)\n",
        "import warnings # current version of seaborn generates a bunch of warnings that we'll ignore\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input/\"))\n",
        "['Iris.csv', 'database.sqlite']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Next, we'll load the Iris flower dataset, which is in the \"../input/\" directory\n",
        "iris = pd.read_csv(\"../input/Iris.csv\") # the iris dataset is now a Pandas DataFrame\n",
        "\n",
        "# Let's see what's in the iris data - Jupyter notebooks print the result of the last thing you do\n",
        "iris.head()"
      ],
      "metadata": {
        "id": "HvBb-7JmR9om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris.describe()"
      ],
      "metadata": {
        "id": "ZMHDcZGZSHNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll use this to make a scatterplot of the Iris features.\n",
        "iris.plot(kind=\"scatter\", x=\"SepalLengthCm\", y=\"SepalWidthCm\")"
      ],
      "metadata": {
        "id": "KdyVu8neSOC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A seaborn jointplot shows bivariate scatterplots and univariate histograms in the same figure\n",
        "sns.jointplot(x=\"SepalLengthCm\", y=\"SepalWidthCm\", data=iris, size=5)"
      ],
      "metadata": {
        "id": "EfL687uBSUDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll use seaborn's FacetGrid to color the scatterplot by species\n",
        "sns.FacetGrid(iris, hue=\"Species\", size=5) \\\n",
        "   .map(plt.scatter, \"SepalLengthCm\", \"SepalWidthCm\") \\\n",
        "   .add_legend()"
      ],
      "metadata": {
        "id": "XPTBWE9TSbfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can look at an individual feature in Seaborn through a boxplot\n",
        "sns.boxplot(x=\"Species\", y=\"PetalLengthCm\", data=iris)"
      ],
      "metadata": {
        "id": "LMeQx7uTSkOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# One way we can extend this plot is adding a layer of individual points on top of\n",
        "# it through Seaborn's striplot\n",
        "\n",
        "# We'll use jitter=True so that all the points don't fall in single vertical lines\n",
        "# above the species\n",
        "# Saving the resulting axes as ax each time causes the resulting plot to be shown\n",
        "# on top of the previous axes\n",
        "ax = sns.boxplot(x=\"Species\", y=\"PetalLengthCm\", data=iris)\n",
        "ax = sns.stripplot(x=\"Species\", y=\"PetalLengthCm\", data=iris, jitter=True, edgecolor=\"gray\")"
      ],
      "metadata": {
        "id": "vGdRlXITSpJq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A violin plot combines the benefits of the previous two plots and simplifies them\n",
        "# Denser regions of the data are fatter, and sparser thiner in a violin plot\n",
        "sns.violinplot(x=\"Species\", y=\"PetalLengthCm\", data=iris, size=6)"
      ],
      "metadata": {
        "id": "dFBu3KfJSuRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A final seaborn plot useful for looking at univariate relations is the kdeplot,\n",
        "# which creates and visualizes a kernel density estimate of the underlying feature\n",
        "sns.FacetGrid(iris, hue=\"Species\", size=6) \\\n",
        "   .map(sns.kdeplot, \"PetalLengthCm\") \\\n",
        "   .add_legend()"
      ],
      "metadata": {
        "id": "wSY_wCJ-S0QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From the pairplot, we'll see that the Iris-setosa species is separataed from the other\n",
        "# two across all feature combinations\n",
        "sns.pairplot(iris.drop(\"Id\", axis=1), hue=\"Species\", size=3)"
      ],
      "metadata": {
        "id": "uk07GM5ES8Fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Box plot grid\n",
        "iris.drop(\"Id\", axis=1).boxplot(by=\"Species\", figsize=(12, 6))"
      ],
      "metadata": {
        "id": "_HgI4-TSTCuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Andrews Curves involve using attributes of samples as coefficients for Fourier series\n",
        "# and then plotting these\n",
        "from pandas.plotting import andrews_curves\n",
        "andrews_curves(iris.drop(\"Id\", axis=1), \"Species\")"
      ],
      "metadata": {
        "id": "UvaOISQ6TIWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Another multivariate visualization technique pandas has is parallel_coordinates\n",
        "# Parallel coordinates plots each feature on a separate column & then draws lines\n",
        "# connecting the features for each data sample\n",
        "from pandas.plotting import parallel_coordinates\n",
        "parallel_coordinates(iris.drop(\"Id\", axis=1), \"Species\")"
      ],
      "metadata": {
        "id": "3jrI8lH8TQCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Which puts each feature as a point on a 2D plane, and then simulates\n",
        "# having each sample attached to those points through a spring weighted\n",
        "# by the relative value for that feature\n",
        "from pandas.plotting import radviz\n",
        "radviz(iris.drop(\"Id\", axis=1), \"Species\")"
      ],
      "metadata": {
        "id": "2mKCHtacTYje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Seperating the data into dependent and independent variables\n",
        "X = iris.iloc[:, :-1].values\n",
        "y = iris.iloc[:, -1].values\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "wihzRqbrTeqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Summary of the predictions made by the classifier\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# Accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('accuracy is',accuracy_score(y_pred,y_test))"
      ],
      "metadata": {
        "id": "Bh9tlwp9TlGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Nearest Neighbours\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "classifier = KNeighborsClassifier(n_neighbors=8)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Summary of the predictions made by the classifier\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# Accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('accuracy is',accuracy_score(y_pred,y_test))"
      ],
      "metadata": {
        "id": "Fwp43OvLTwxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " precision    recall  f1-score   support\n",
        "\n",
        "    Iris-setosa       1.00      1.00      1.00        11\n",
        "Iris-versicolor       1.00      1.00      1.00        13\n",
        " Iris-virginica       1.00      1.00      1.00         6\n",
        "\n",
        "       accuracy                           1.00        30\n",
        "      macro avg       1.00      1.00      1.00        30\n",
        "   weighted avg       1.00      1.00      1.00        30\n",
        "\n",
        "[[11  0  0]\n",
        " [ 0 13  0]\n",
        " [ 0  0  6]]\n",
        "accuracy is 1.0"
      ],
      "metadata": {
        "id": "l-EHuSR2T2bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Support Vector Machine's \n",
        "from sklearn.svm import SVC\n",
        "\n",
        "classifier = SVC()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Summary of the predictions made by the classifier\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# Accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('accuracy is',accuracy_score(y_pred,y_test))"
      ],
      "metadata": {
        "id": "mVa3XkwHT8Wo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decision Tree's\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "classifier = DecisionTreeClassifier()\n",
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Summary of the predictions made by the classifier\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# Accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('accuracy is',accuracy_score(y_pred,y_test))"
      ],
      "metadata": {
        "id": "4kxO_H7SUBjN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " precision    recall  f1-score   support\n",
        "\n",
        "    Iris-setosa       1.00      1.00      1.00        11\n",
        "Iris-versicolor       0.93      1.00      0.96        13\n",
        " Iris-virginica       1.00      0.83      0.91         6\n",
        "\n",
        "       accuracy                           0.97        30\n",
        "      macro avg       0.98      0.94      0.96        30\n",
        "   weighted avg       0.97      0.97      0.97        30\n",
        "\n",
        "[[11  0  0]\n",
        " [ 0 13  0]\n",
        " [ 0  1  5]]\n",
        "accuracy is 0.9666666666666667"
      ],
      "metadata": {
        "id": "_wsEwoR3ULn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gaussian Naive Bayes\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier = GaussianNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Summary of the predictions made by the classifier\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# Accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('accuracy is',accuracy_score(y_pred,y_test))"
      ],
      "metadata": {
        "id": "DuoILU8aUQMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "precision    recall  f1-score   support\n",
        "\n",
        "    Iris-setosa       1.00      1.00      1.00        11\n",
        "Iris-versicolor       1.00      1.00      1.00        13\n",
        " Iris-virginica       1.00      1.00      1.00         6\n",
        "\n",
        "       accuracy                           1.00        30\n",
        "      macro avg       1.00      1.00      1.00        30\n",
        "   weighted avg       1.00      1.00      1.00        30\n",
        "\n",
        "[[11  0  0]\n",
        " [ 0 13  0]\n",
        " [ 0  0  6]]\n",
        "accuracy is 1.0"
      ],
      "metadata": {
        "id": "LVXSs_bXUWtl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multinomial Naive Bayes\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "classifier = MultinomialNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Summary of the predictions made by the classifier\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# Accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('accuracy is',accuracy_score(y_pred,y_test))"
      ],
      "metadata": {
        "id": "EnYg9SbmUbYm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " precision    recall  f1-score   support\n",
        "\n",
        "    Iris-setosa       1.00      0.91      0.95        11\n",
        "Iris-versicolor       0.83      0.77      0.80        13\n",
        " Iris-virginica       0.62      0.83      0.71         6\n",
        "\n",
        "       accuracy                           0.83        30\n",
        "      macro avg       0.82      0.84      0.82        30\n",
        "   weighted avg       0.85      0.83      0.84        30\n",
        "\n",
        "[[10  1  0]\n",
        " [ 0 10  3]\n",
        " [ 0  1  5]]\n",
        "accuracy is 0.8333333333333334"
      ],
      "metadata": {
        "id": "zKMrWbH5Uges"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bernoulli Naive Bayes\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "classifier = BernoulliNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Summary of the predictions made by the classifier\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# Accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('accuracy is',accuracy_score(y_pred,y_test))"
      ],
      "metadata": {
        "id": "8nGeOdpQUnrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " precision    recall  f1-score   support\n",
        "\n",
        "    Iris-setosa       0.00      0.00      0.00        11\n",
        "Iris-versicolor       0.00      0.00      0.00        13\n",
        " Iris-virginica       0.20      1.00      0.33         6\n",
        "\n",
        "       accuracy                           0.20        30\n",
        "      macro avg       0.07      0.33      0.11        30\n",
        "   weighted avg       0.04      0.20      0.07        30\n",
        "\n",
        "[[ 0  0 11]\n",
        " [ 0  0 13]\n",
        " [ 0  0  6]]\n",
        "accuracy is 0.2"
      ],
      "metadata": {
        "id": "mfoVoPukUtK7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Complement Naive Bayes\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "classifier = ComplementNB()\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "\n",
        "# Summary of the predictions made by the classifier\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "# Accuracy score\n",
        "from sklearn.metrics import accuracy_score\n",
        "print('accuracy is',accuracy_score(y_pred,y_test))"
      ],
      "metadata": {
        "id": "EBg6-iZvUyJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " precision    recall  f1-score   support\n",
        "\n",
        "    Iris-setosa       0.69      1.00      0.81        11\n",
        "Iris-versicolor       0.00      0.00      0.00        13\n",
        " Iris-virginica       0.43      1.00      0.60         6\n",
        "\n",
        "       accuracy                           0.57        30\n",
        "      macro avg       0.37      0.67      0.47        30\n",
        "   weighted avg       0.34      0.57      0.42        30\n",
        "\n",
        "[[11  0  0]\n",
        " [ 5  0  8]\n",
        " [ 0  0  6]]\n",
        "accuracy is 0.5666666666666667"
      ],
      "metadata": {
        "id": "yuTlhqjmU7rG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "classifiers = [\n",
        "    GaussianNB(),\n",
        "    MultinomialNB(),\n",
        "    BernoulliNB(),\n",
        "    ComplementNB(),               \n",
        "                  ]\n",
        " \n",
        "# Logging for Visual Comparison\n",
        "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
        "log = pd.DataFrame(columns=log_cols)\n",
        " \n",
        "for clf in classifiers:\n",
        "    clf.fit(X_train, y_train)\n",
        "    name = clf.__class__.__name__\n",
        "    \n",
        "    print(\"=\"*30)\n",
        "    print(name)"
      ],
      "metadata": {
        "id": "muk97GIOU90t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " print('****Results****')\n",
        "    train_predictions = clf.predict(X_test)\n",
        "    acc = accuracy_score(y_test, train_predictions)\n",
        "    print(\"Accuracy: {:.4%}\".format(acc))\n",
        "    \n",
        "    log_entry = pd.DataFrame([[name, acc*100, 11]], columns=log_cols)\n",
        "    log = log.append(log_entry)\n",
        "    \n",
        "    print(\"=\"*30)"
      ],
      "metadata": {
        "id": "wZ3_NSHGVNq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set_color_codes(\"muted\")\n",
        "sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\")\n",
        "\n",
        "plt.xlabel('Accuracy %')\n",
        "plt.title('Classifier Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MyGzjPraVVUE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}